{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51e75caf",
   "metadata": {},
   "source": [
    "# Multimodal Training & Evaluation\n",
    "\n",
    "## Goals\n",
    "- Tabular-only baseline (XGBoost/RandomForest) vs. Multimodal (ResNet18 + MLP)\n",
    "- Train/val split, metrics: RMSE, R²\n",
    "- Generate Grad-CAM overlays\n",
    "- Export `outputs/submission.csv`\n",
    "\n",
    "## Outline\n",
    "1. Load cleaned data and image paths\n",
    "2. Fit StandardScaler on tabular features\n",
    "3. Build PyTorch datasets/dataloaders\n",
    "4. Train FusionModel (late fusion), log metrics per epoch\n",
    "5. Evaluate on val set; compare with tabular-only XGBoost\n",
    "6. Grad-CAM visualization on val samples\n",
    "7. Predict test set and save CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef443b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.config import cfg\n",
    "from src.datasets import HousePriceDataset\n",
    "from src.model import FusionModel\n",
    "from src.gradcam import GradCAM\n",
    "from src.utils import seed_everything\n",
    "\n",
    "# Set seed for reproducibility\n",
    "seed_everything(cfg.seed)\n",
    "print(f\"Using device: {cfg.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4addea",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43023603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train data\n",
    "train_df = pd.read_excel(f\"../{cfg.train_xlsx}\")\n",
    "test_df = pd.read_excel(f\"../{cfg.test_xlsx}\")\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "\n",
    "# Train-validation split\n",
    "train_data, val_data = train_test_split(\n",
    "    train_df, \n",
    "    test_size=cfg.val_split, \n",
    "    random_state=cfg.seed\n",
    ")\n",
    "print(f\"Train samples: {len(train_data)}, Val samples: {len(val_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe91087",
   "metadata": {},
   "source": [
    "## 2. Tabular Baseline (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f6f34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare tabular features\n",
    "X_train = train_data[cfg.tab_feats].values\n",
    "X_val = val_data[cfg.tab_feats].values\n",
    "y_train = train_data[cfg.target].values\n",
    "y_val = val_data[cfg.target].values\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Train XGBoost baseline\n",
    "xgb_model = XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=cfg.seed\n",
    ")\n",
    "xgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate\n",
    "xgb_pred = xgb_model.predict(X_val_scaled)\n",
    "xgb_rmse = np.sqrt(mean_squared_error(y_val, xgb_pred))\n",
    "xgb_r2 = r2_score(y_val, xgb_pred)\n",
    "\n",
    "print(f\"XGBoost Baseline Results:\")\n",
    "print(f\"  RMSE: ${xgb_rmse:,.2f}\")\n",
    "print(f\"  R²: {xgb_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b759453",
   "metadata": {},
   "source": [
    "## 3. Multimodal Model Setup\n",
    "\n",
    "**Note:** Before running this section, make sure you have:\n",
    "1. Set your API key in the `.env` file (MAPBOX_TOKEN or GOOGLE_API_KEY)\n",
    "2. Run the data fetcher to download satellite images:\n",
    "```bash\n",
    "python -m src.data_fetcher\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc86c38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if satellite images exist\n",
    "import os\n",
    "image_dir = f\"../{cfg.image_dir}\"\n",
    "\n",
    "if os.path.exists(image_dir):\n",
    "    images = [f for f in os.listdir(image_dir) if f.endswith('.png')]\n",
    "    print(f\"Found {len(images)} satellite images in {image_dir}\")\n",
    "else:\n",
    "    print(f\"WARNING: Image directory not found: {image_dir}\")\n",
    "    print(\"Please run: python -m src.data_fetcher\")\n",
    "    print(\"Make sure your API key is set in .env file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62220767",
   "metadata": {},
   "source": [
    "## 4. Train Multimodal Model\n",
    "\n",
    "Run the full training pipeline using the `train.py` script:\n",
    "```bash\n",
    "python -m src.train\n",
    "```\n",
    "\n",
    "Or continue below to train interactively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f227c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets (only runs if images exist)\n",
    "if os.path.exists(image_dir) and len(os.listdir(image_dir)) > 0:\n",
    "    train_dataset = HousePriceDataset(train_data, scaler, cfg.image_dir, is_train=True)\n",
    "    val_dataset = HousePriceDataset(val_data, scaler, cfg.image_dir, is_train=False)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=cfg.batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=cfg.batch_size, shuffle=False, num_workers=0)\n",
    "    \n",
    "    print(f\"Train dataset: {len(train_dataset)} samples\")\n",
    "    print(f\"Val dataset: {len(val_dataset)} samples\")\n",
    "else:\n",
    "    print(\"Skipping dataset creation - no images found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406a5302",
   "metadata": {},
   "source": [
    "## 5. Results Summary\n",
    "\n",
    "After training completes, you'll find:\n",
    "- **Model checkpoint:** `models/best_model.pt`\n",
    "- **Predictions:** `outputs/submission.csv`\n",
    "- **Grad-CAM visualizations:** `outputs/gradcam/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d09c7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results comparison\n",
    "print(\"=\" * 50)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\n{'Model':<25} {'RMSE':>12} {'R²':>10}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'XGBoost (Tabular Only)':<25} ${xgb_rmse:>10,.0f} {xgb_r2:>10.4f}\")\n",
    "print(\"\\n(Multimodal results will appear after training)\")\n",
    "print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
