{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51e75caf",
   "metadata": {},
   "source": [
    "# ðŸ  House Price Prediction - Hybrid Model Training\n",
    "\n",
    "## Overview\n",
    "This notebook demonstrates the **Hybrid CNN + XGBoost Pipeline** for house price prediction:\n",
    "1. **PyTorch Model**: ResNet18 CNN + Tabular MLP fusion (256 + 64 = 320 features)\n",
    "2. **XGBoost Model**: Trained on deep features extracted from PyTorch model\n",
    "3. **Automatic Selection**: Best model (by RÂ²) generates final predictions\n",
    "\n",
    "## Pipeline Steps\n",
    "1. Load data and satellite images\n",
    "2. Train PyTorch HybridMultimodalModel\n",
    "3. Extract 320-dim deep features\n",
    "4. Train XGBoost on those features\n",
    "5. Compare models and pick winner\n",
    "6. Generate Grad-CAM visualizations\n",
    "7. Save `submission.csv` using best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef443b83",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.config import cfg\n",
    "from src.data_fetcher import download\n",
    "from src.datasets import HouseDataset\n",
    "from src.model import HybridMultimodalModel\n",
    "from src.gradcam import GradCAM\n",
    "\n",
    "# Set seed for reproducibility\n",
    "torch.manual_seed(cfg.seed)\n",
    "np.random.seed(cfg.seed)\n",
    "\n",
    "print(f\"Using device: {cfg.device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4addea",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43023603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train and test data\n",
    "train_df = pd.read_excel(f\"../{cfg.train_xlsx}\")\n",
    "test_df = pd.read_excel(f\"../{cfg.test_xlsx}\")\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "print(f\"\\nTabular features: {cfg.tab_feats}\")\n",
    "\n",
    "# Fetch/load satellite images (uses free ESRI - no API key!)\n",
    "print(\"\\nðŸ“¡ Fetching satellite images...\")\n",
    "img_paths = download(pd.concat([train_df, test_df], axis=0))\n",
    "\n",
    "# Filter rows with valid images\n",
    "train_df = train_df[train_df[\"id\"].isin(img_paths.keys())]\n",
    "test_df = test_df[test_df[\"id\"].isin(img_paths.keys())]\n",
    "print(f\"\\nTrain samples with images: {len(train_df)}\")\n",
    "print(f\"Test samples with images: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe91087",
   "metadata": {},
   "source": [
    "## 2. Prepare Data & Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f6f34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale tabular features\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_df[cfg.tab_feats].astype(float))\n",
    "\n",
    "# Train-validation split\n",
    "tr_df, val_df = train_test_split(train_df, test_size=cfg.val_split, random_state=cfg.seed)\n",
    "print(f\"Training set: {len(tr_df)}\")\n",
    "print(f\"Validation set: {len(val_df)}\")\n",
    "\n",
    "# Create datasets\n",
    "tr_ds = HouseDataset(tr_df, img_paths, scaler, train=True)\n",
    "val_ds = HouseDataset(val_df, img_paths, scaler, train=True)\n",
    "te_ds = HouseDataset(test_df, img_paths, scaler, train=False)\n",
    "\n",
    "# Create dataloaders\n",
    "tr_loader = DataLoader(tr_ds, batch_size=cfg.batch_size, shuffle=True, num_workers=cfg.num_workers)\n",
    "val_loader = DataLoader(val_ds, batch_size=cfg.batch_size, shuffle=False, num_workers=cfg.num_workers)\n",
    "te_loader = DataLoader(te_ds, batch_size=cfg.batch_size, shuffle=False, num_workers=cfg.num_workers)\n",
    "\n",
    "print(f\"\\nDataLoaders created with batch_size={cfg.batch_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b759453",
   "metadata": {},
   "source": [
    "## 3. Train PyTorch HybridMultimodalModel\n",
    "\n",
    "The model architecture:\n",
    "- **Visual Hemisphere**: ResNet18 â†’ 256 features (with BatchNorm + Dropout)\n",
    "- **Logical Hemisphere**: Tabular MLP â†’ 64 features (with BatchNorm + Dropout)  \n",
    "- **Combined**: 320 features â†’ Regressor head â†’ Price prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc86c38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def rmse(pred, true):\n",
    "    return math.sqrt(mean_squared_error(true, pred))\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for img, tab, y in loader:\n",
    "        img, tab, y = img.to(device), tab.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(img, tab)\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * len(y)\n",
    "    return total_loss / len(loader.dataset)\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_model(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    ys, ps = [], []\n",
    "    total_loss = 0\n",
    "    for img, tab, y in loader:\n",
    "        img, tab, y = img.to(device), tab.to(device), y.to(device)\n",
    "        pred = model(img, tab)\n",
    "        loss = criterion(pred, y)\n",
    "        total_loss += loss.item() * len(y)\n",
    "        ys.append(y.cpu().numpy())\n",
    "        ps.append(pred.cpu().numpy())\n",
    "    ys = np.concatenate(ys)\n",
    "    ps = np.concatenate(ps)\n",
    "    return total_loss / len(loader.dataset), rmse(ps, ys), r2_score(ys, ps)\n",
    "\n",
    "# Initialize model\n",
    "device = cfg.device\n",
    "model = HybridMultimodalModel(tabular_input_dim=len(cfg.tab_feats)).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "print(f\"Model initialized on {device}\")\n",
    "print(f\"Feature dimension: 256 (visual) + 64 (tabular) = 320 combined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62220767",
   "metadata": {},
   "source": [
    "## 4. Training Loop\n",
    "\n",
    "Train for configured epochs and track best model by RMSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f227c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "best_rmse = float(\"inf\")\n",
    "best_r2 = float(\"-inf\")\n",
    "history = {\"train_loss\": [], \"val_rmse\": [], \"val_r2\": []}\n",
    "\n",
    "print(f\"Training for {cfg.epochs} epochs...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for epoch in tqdm(range(cfg.epochs), desc=\"Training\"):\n",
    "    tr_loss = train_one_epoch(model, tr_loader, optimizer, criterion, device)\n",
    "    val_loss, val_rmse, val_r2 = eval_model(model, val_loader, criterion, device)\n",
    "    \n",
    "    history[\"train_loss\"].append(tr_loss)\n",
    "    history[\"val_rmse\"].append(val_rmse)\n",
    "    history[\"val_r2\"].append(val_r2)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{cfg.epochs} | Train Loss: {tr_loss:.4f} | Val RMSE: ${val_rmse:,.0f} | Val RÂ²: {val_r2:.4f}\")\n",
    "    \n",
    "    if val_rmse < best_rmse:\n",
    "        best_rmse = val_rmse\n",
    "        best_r2 = val_r2\n",
    "        torch.save({\"model\": model.state_dict(), \"epoch\": epoch+1, \"best_rmse\": best_rmse, \"best_r2\": best_r2}, \n",
    "                   f\"../models/best_model.pt\")\n",
    "        print(f\"   âœ… New best model saved!\")\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"âœ… Best PyTorch Model: RMSE=${best_rmse:,.0f}, RÂ²={best_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406a5302",
   "metadata": {},
   "source": [
    "## 5. Train XGBoost on Deep Features\n",
    "\n",
    "Extract 320-dim features from PyTorch model and train XGBoost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d09c7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features for XGBoost\n",
    "def extract_features(model, loader, device, include_targets=True):\n",
    "    model.eval()\n",
    "    features_list, targets_list, ids_list = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            if include_targets:\n",
    "                img, tab, y = batch\n",
    "                targets_list.extend(y.numpy())\n",
    "            else:\n",
    "                img, tab, pid = batch\n",
    "                ids_list.extend(pid.tolist() if hasattr(pid, 'tolist') else list(pid))\n",
    "            img, tab = img.to(device), tab.to(device)\n",
    "            feats = model.get_features_only(img, tab)\n",
    "            features_list.append(feats)\n",
    "    features = np.vstack(features_list)\n",
    "    if include_targets:\n",
    "        return features, np.array(targets_list)\n",
    "    return features, ids_list\n",
    "\n",
    "# Extract features\n",
    "X_train, y_train = extract_features(model, tr_loader, device)\n",
    "X_val, y_val = extract_features(model, val_loader, device)\n",
    "print(f\"Training features: {X_train.shape}\")\n",
    "print(f\"Validation features: {X_val.shape}\")\n",
    "\n",
    "# Train XGBoost\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=200, learning_rate=0.1, max_depth=6,\n",
    "    min_child_weight=1, subsample=0.8, colsample_bytree=0.8,\n",
    "    random_state=cfg.seed, n_jobs=-1\n",
    ")\n",
    "xgb_model.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)\n",
    "print(\"âœ… XGBoost Training Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22df4ac0",
   "metadata": {},
   "source": [
    "## 6. Model Comparison & Winner Selection\n",
    "\n",
    "Compare PyTorch vs XGBoost and select best by RÂ² score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dab0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch predictions on validation\n",
    "model.eval()\n",
    "y_pred_pt = []\n",
    "y_true = []\n",
    "with torch.no_grad():\n",
    "    for img, tab, y in val_loader:\n",
    "        img, tab = img.to(device), tab.to(device)\n",
    "        pred = model(img, tab)\n",
    "        y_pred_pt.extend(pred.cpu().numpy())\n",
    "        y_true.extend(y.numpy())\n",
    "y_pred_pt = np.array(y_pred_pt)\n",
    "y_true = np.array(y_true)\n",
    "\n",
    "# PyTorch metrics\n",
    "pt_rmse = rmse(y_pred_pt, y_true)\n",
    "pt_r2 = r2_score(y_true, y_pred_pt)\n",
    "pt_mae = mean_absolute_error(y_true, y_pred_pt)\n",
    "\n",
    "# XGBoost metrics\n",
    "y_pred_xgb = xgb_model.predict(X_val)\n",
    "xgb_rmse_val = rmse(y_pred_xgb, y_val)\n",
    "xgb_r2 = r2_score(y_val, y_pred_xgb)\n",
    "xgb_mae = mean_absolute_error(y_val, y_pred_xgb)\n",
    "\n",
    "# Print comparison\n",
    "print(\"=\" * 60)\n",
    "print(\"ðŸ† MODEL COMPARISON (Validation Set)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n{'Model':<30} {'RMSE':>12} {'RÂ²':>10} {'MAE':>12}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'PyTorch (CNN + Tabular)':<30} ${pt_rmse:>10,.0f} {pt_r2:>10.4f} ${pt_mae:>10,.0f}\")\n",
    "print(f\"{'XGBoost (on Deep Features)':<30} ${xgb_rmse_val:>10,.0f} {xgb_r2:>10.4f} ${xgb_mae:>10,.0f}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Declare winner\n",
    "if xgb_r2 > pt_r2:\n",
    "    print(f\"\\nðŸ† WINNER: XGBoost on Deep Features! (RÂ²: {xgb_r2:.4f})\")\n",
    "    winner = \"xgboost\"\n",
    "else:\n",
    "    print(f\"\\nðŸ† WINNER: PyTorch End-to-End Model! (RÂ²: {pt_r2:.4f})\")\n",
    "    winner = \"pytorch\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17564192",
   "metadata": {},
   "source": [
    "## 7. Generate Test Predictions\n",
    "\n",
    "Save `submission.csv` using the best model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb95115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract test features\n",
    "X_test, test_ids = extract_features(model, te_loader, device, include_targets=False)\n",
    "\n",
    "# Generate predictions from the model with best RÂ² score\n",
    "if xgb_r2 > pt_r2:\n",
    "    best_preds = xgb_model.predict(X_test)\n",
    "    best_model_name = \"XGBoost\"\n",
    "    best_r2_score = xgb_r2\n",
    "else:\n",
    "    best_preds = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for img, tab, pid in te_loader:\n",
    "            img, tab = img.to(device), tab.to(device)\n",
    "            pred = model(img, tab).cpu().numpy()\n",
    "            best_preds.extend(pred.tolist())\n",
    "    best_model_name = \"PyTorch\"\n",
    "    best_r2_score = pt_r2\n",
    "\n",
    "# Save only the best model's submission\n",
    "os.makedirs(\"../outputs\", exist_ok=True)\n",
    "submission = pd.DataFrame({\"id\": test_ids, \"predicted_price\": best_preds})\n",
    "submission.to_csv(\"../outputs/submission.csv\", index=False)\n",
    "print(f\"âœ… Saved: outputs/submission.csv (using {best_model_name} with RÂ²: {best_r2_score:.4f})\")\n",
    "print(f\"\\nFirst 5 predictions:\")\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd67236",
   "metadata": {},
   "source": [
    "## 8. Grad-CAM Visualization\n",
    "\n",
    "Generate heatmaps showing which parts of satellite images influence predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68f01d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from src.train import run_gradcam\n",
    "\n",
    "# Generate Grad-CAM visualizations\n",
    "run_gradcam(model, val_ds, \"../outputs\")\n",
    "print(\"âœ… Grad-CAM visualizations saved to outputs/gradcam/\")\n",
    "\n",
    "# Display a sample\n",
    "gradcam_dir = \"../outputs/gradcam\"\n",
    "if os.path.exists(gradcam_dir):\n",
    "    samples = [f for f in os.listdir(gradcam_dir) if f.endswith('.png')][:4]\n",
    "    if samples:\n",
    "        fig, axes = plt.subplots(1, len(samples), figsize=(16, 4))\n",
    "        for ax, sample in zip(axes, samples):\n",
    "            img = plt.imread(os.path.join(gradcam_dir, sample))\n",
    "            ax.imshow(img)\n",
    "            ax.set_title(sample.replace('.png', ''))\n",
    "            ax.axis('off')\n",
    "        plt.suptitle(\"Grad-CAM: What the model sees\", fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce1623c",
   "metadata": {},
   "source": [
    "## 9. Training History Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd5b699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].plot(history[\"train_loss\"], 'b-', label='Train Loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(history[\"val_rmse\"], 'r-', label='Val RMSE')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('RMSE ($)')\n",
    "axes[1].set_title('Validation RMSE')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[2].plot(history[\"val_r2\"], 'g-', label='Val RÂ²')\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('RÂ²')\n",
    "axes[2].set_title('Validation RÂ²')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"âœ… TRAINING COMPLETE!\")\n",
    "print(f\"   Winner: {winner.upper()} (RÂ²: {xgb_r2:.4f if winner == 'xgboost' else pt_r2:.4f})\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
